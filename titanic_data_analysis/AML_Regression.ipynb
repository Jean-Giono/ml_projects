{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used here is about some houses prices. You can find more information about it on this [website](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all library needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_decomposition\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation of the data for the machine learning (ML) models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train1.csv')\n",
    "test_df = pd.read_csv('test1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll just replace all the missing values by their corresponding features means as they're all numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train_df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(train_df.drop('SalePrice', axis=1).drop('Id', axis=1))\n",
    "X_train = X_train.fillna(X_train.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.get_dummies(test_df.drop('Id', axis=1))\n",
    "X_test = X_test.fillna(X_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking only the train data that aren't in the test set\n",
    "for i in list(X_train.columns):\n",
    "    if not i in list(X_test.columns):\n",
    "        X_train = X_train.drop(i, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building some ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X_train, Y)\n",
    "acc_reg = round(reg.score(X_train, Y) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine for Regression (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR(gamma='auto')\n",
    "svr.fit(X_train, Y)\n",
    "acc_svr = round(svr.score(X_train, Y) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestRegressor(n_estimators=100)\n",
    "random_forest.fit(X_train, Y)\n",
    "acc_random_forest = round(random_forest.score(X_train, Y) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boost = GradientBoostingRegressor()\n",
    "gradient_boost.fit(X_train, Y)\n",
    "acc_gradient_boost = round(gradient_boost.score(X_train, Y) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see which one is the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98.22</th>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96.64</th>\n",
       "      <td>Gradient Boosting Regressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91.72</th>\n",
       "      <td>Linear Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-5.09</th>\n",
       "      <td>SVR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model\n",
       "Score                              \n",
       " 98.22                Random Forest\n",
       " 96.64  Gradient Boosting Regressor\n",
       " 91.72            Linear Regression\n",
       "-5.09                           SVR"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['SVR', 'Linear Regression', 'Random Forest', 'Gradient Boosting Regressor'],\n",
    "    'Score': [acc_svr, acc_reg, acc_random_forest, acc_gradient_boost]})\n",
    "result_df = results.sort_values(by='Score', ascending=False)\n",
    "result_df = result_df.set_index('Score')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the Random Forest regressor goes on the first place. However, let's check how it performs when using cross validation.\n",
    "The cross validation idea is to split our training set into k-folds. Our model would be trained and evaluated k times using different fold for evaluation everytime, while it would be trained on the remaining k-1 folds.\n",
    "Here we use k = 10 folds. The score used here is the MSE (mean squared error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [6.27378324e+08 6.51009833e+08 4.87253519e+08 1.50458445e+09\n",
      " 1.13304490e+09 6.94430084e+08 5.88324386e+08 5.86830313e+08\n",
      " 1.75345429e+09 7.43044327e+08]\n",
      "Mean: 876935442.0479609\n",
      "Standard Deviation: 413725285.498749\n"
     ]
    }
   ],
   "source": [
    "#cval = LeaveOneOut().get_n_splits(X_train)\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "scores = cross_val_score(rf, X_train, Y, cv=10, scoring = make_scorer(mean_squared_error))\n",
    "print(\"Scores:\", scores)\n",
    "print(\"Mean:\", scores.mean())\n",
    "print(\"Standard Deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models hyperparameters tuning\n",
    "\n",
    "There are many hyparameters, so we cannot tune the model using all of them. We select some of them, and each of them has a list of values. In the end, the best combination is shown.\n",
    "We'll only tune the hyperparameters of the random forest model as it's the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'auto',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {   \"min_samples_leaf\" : [1, 2, 4],\n",
    "                  \"min_samples_split\" : [2, 5, 10],\n",
    "                  \"n_estimators\": [100, 200],\n",
    "             \"max_features\": ['auto','sqrt','log2']}\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=1, n_jobs=-1, oob_score=True)\n",
    "clf = GridSearchCV(estimator=rf, param_grid=param_grid, n_jobs=-1,cv=10,iid=False)\n",
    "clf.fit(X_train, Y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's the new parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.2"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestRegressor( min_samples_leaf = 1, \n",
    "                                       min_samples_split = 5,   \n",
    "                                       n_estimators=200, \n",
    "                                       max_features='auto', \n",
    "                                       oob_score=True, \n",
    "                                       random_state=1, \n",
    "                                       n_jobs=-1)\n",
    "\n",
    "random_forest.fit(X_train, Y)\n",
    "Y_prediction = random_forest.predict(X_test)\n",
    "\n",
    "round(random_forest.oob_score_, 3)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a proper model, we can start evaluating it’s performace in a more accurate way. Before we used, the oob score to do so and now we're going to use other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions to submit to kaggle\n",
    "sub_data = X_test\n",
    "sub_data['SalePrice'] = Y_prediction\n",
    "sub_data['Id'] = range(1461,2920)\n",
    "sub_data = sub_data.loc[:,['Id','SalePrice']]\n",
    "sub_data.to_csv('submission_data1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submission, I got **0.14803** as a score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
